{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cb494f89-b12b-439d-876a-923d08c774f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\\begin{tabular}{llrrrrrrrrrr}\n",
      "\\toprule\n",
      " & File & ComplexContainerComprehension & LargeClass & LongBaseClassList & LongLambdaFunction & LongMessageChain & LongMethod & LongParameterList & LongScopeChaining & LongTernaryConditionalExpression & MultiplyNestedContainer \\\\\n",
      "Metric & Predictor &  &  &  &  &  &  &  &  &  &  \\\\\n",
      "\\midrule\n",
      "\\multirow[t]{3}{*}{F1-Score} & experience-based & 0.636364 & 0.875000 & 0.984127 & 0.835821 & 0.916667 & 0.961538 & 0.984127 & 0.857143 & 0.764706 & 0.950820 \\\\\n",
      " & statistics-based & 0.846154 & 0.846154 & 0.861111 & 0.900000 & 0.974359 & 0.862069 & 0.876712 & 0.971429 & 0.851852 & 0.857143 \\\\\n",
      " & tuning machine & 0.915254 & 0.933333 & 0.984127 & 0.965517 & 0.974359 & 0.961538 & 0.984127 & 0.971429 & 0.896552 & 0.950820 \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow[t]{3}{*}{Precision} & experience-based & 0.466667 & 0.777778 & 0.968750 & 0.717949 & 0.970588 & 0.925926 & 1.000000 & 0.750000 & 0.619048 & 0.935484 \\\\\n",
      " & statistics-based & 0.916667 & 0.916667 & 0.756098 & 0.843750 & 0.950000 & 0.757576 & 0.780488 & 1.000000 & 0.821429 & 0.923077 \\\\\n",
      " & tuning machine & 0.870968 & 0.875000 & 0.968750 & 0.933333 & 0.950000 & 0.925926 & 1.000000 & 1.000000 & 0.812500 & 0.935484 \\\\\n",
      "\\cline{1-12}\n",
      "\\multirow[t]{3}{*}{Recall} & experience-based & 1.000000 & 1.000000 & 1.000000 & 1.000000 & 0.868421 & 1.000000 & 0.968750 & 1.000000 & 1.000000 & 0.966667 \\\\\n",
      " & statistics-based & 0.785714 & 0.785714 & 1.000000 & 0.964286 & 1.000000 & 1.000000 & 1.000000 & 0.944444 & 0.884615 & 0.800000 \\\\\n",
      " & tuning machine & 0.964286 & 1.000000 & 1.000000 & 1.000000 & 1.000000 & 1.000000 & 0.968750 & 0.944444 & 1.000000 & 0.966667 \\\\\n",
      "\\cline{1-12}\n",
      "\\bottomrule\n",
      "\\end{tabular}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import precision_score, recall_score, f1_score\n",
    "import glob\n",
    "\n",
    "# Define the folder and file pattern\n",
    "folder_path = 'validation_repository/'  # Replace with your folder path\n",
    "file_pattern = '*.csv'  # Adjust if needed for specific file types\n",
    "\n",
    "# Prediction columns and ground truth column\n",
    "predictions = ['experience-based', 'statistics-based', 'tuning machine']\n",
    "ground_truth = 'manual inspection'\n",
    "\n",
    "# Initialize a dictionary to store metrics for all files\n",
    "results = []\n",
    "\n",
    "# Loop through each file in the folder\n",
    "for file in glob.glob(folder_path + file_pattern):\n",
    "    # Extract file name (without extension) for column naming\n",
    "    file_name = file.split('/')[-1].replace('.csv', '')\n",
    "\n",
    "    # Load the data\n",
    "    data = pd.read_csv(file)\n",
    "\n",
    "    # Ensure binary values in the relevant columns\n",
    "    for column in predictions + [ground_truth]:\n",
    "        if not data[column].isin([0, 1]).all():\n",
    "            raise ValueError(f\"Column {column} in {file} contains non-binary values. Please preprocess the data.\")\n",
    "\n",
    "    # Calculate metrics for each prediction method\n",
    "    for pred in predictions:\n",
    "        precision = precision_score(data[ground_truth], data[pred])\n",
    "        recall = recall_score(data[ground_truth], data[pred])\n",
    "        f1 = f1_score(data[ground_truth], data[pred])\n",
    "        \n",
    "        # Add metrics to results as a dictionary\n",
    "        results.append({\n",
    "            'File': file_name,\n",
    "            'Predictor': pred,\n",
    "            'Precision': f\"{precision:.2f}\",\n",
    "            'Recall': f\"{recall:.2f}\",\n",
    "            'F1-Score': f\"{f1:.2f}\"\n",
    "        })\n",
    "\n",
    "# Convert results to a DataFrame\n",
    "results_df = pd.DataFrame(results)\n",
    "\n",
    "# Pivot the DataFrame to prepare for LaTeX table\n",
    "latex_table = results_df.melt(id_vars=['File', 'Predictor'], \n",
    "                              var_name='Metric', \n",
    "                              value_name='Value').pivot(index=['Metric', 'Predictor'], \n",
    "                                                        columns='File', \n",
    "                                                        values='Value')\n",
    "\n",
    "# Convert the pivoted table to LaTeX\n",
    "latex_code = latex_table.to_latex(index=True, multirow=True)\n",
    "print(latex_code)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "005bb12c-c3e9-420e-825e-0f608589e55d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
